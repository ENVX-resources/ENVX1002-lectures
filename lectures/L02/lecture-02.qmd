---
title: "Lecture 02: Introduction to statistical programming"
author: Januar Harianto
format: soles-revealjs
embed-resources: false
---


# Learning outcomes

By completing this lecture, you will be able to:

1. Understand fundamental statistical concepts in plain language
2. Learn how R implements these statistical concepts
3. Write R code to calculate measures of central tendency and spread
4. Choose appropriate statistical measures for different types of data
5. Apply statistical programming to real data analysis



## Getting Started Checklist

::: {.callout-tip}
## Installation Support
If you have any trouble with installation:

1. Check our [troubleshooting guide](https://cran.r-project.org/doc/FAQ/R-FAQ.html)
2. Ask on the unit discussion board
3. Visit help sessions
4. Email the teaching team
:::

### Essential Setup
- [ ] Installed [**R**](https://cran.r-project.org/)
- [ ] Installed [**RStudio**](https://posit.co/download/rstudio-desktop/)
- [ ] Know some [Markdown basics](https://quarto.org/docs/authoring/markdown-basics.html)


# Statistical computing: A quick history

## From calculators to computers

::: {layout-ncol=2}

![1800s: Mechanical calculators. [Source](https://commons.wikimedia.org/wiki/File:Mechanical_calculators_Keyboards.png)](images/calculator1800s.png){height=400 fig-align="left"}

![1960s: Statistical software BMDP and SPSS (not in image). [Source](https://economicsnetwork.ac.uk/cheer/ch10_3/ch10_3p21.htm)](images/bmdp.gif){height=400}

:::

## Statistical softare in the 1970s

::: {layout-ncol=2}

![1970s: SAS (Statistical Analysis System) [Source](https://data-flair.training/blogs/sas-software/)](images/sas-stat.webp){height=300 fig-align="left"}

![1976: Birth of S at Bell Labs. S-PLUS debuts in 1988. [Source](https://solutionmetrics.com.au/splus/)](images/splus.png){height=300}

:::

# The R story
- Created at University of Auckland, New Zealand in 1993
- Named after creators (Ross & Robert) -- and inspired by S programming language
- Developed rapidly in the 2000s
- Designed specifically for statistical computing and graphics, but now used in many fields

![The R graphical user interface. [Source](https://users.ssc.wisc.edu/~hemken/Rworkshops/interface/RConsole.html)](images/rgui.jpeg){fig-align="left"}

## R in today's world
- Leading tool in data science and statistics (although Python leads in majority of machine learning workflows)
- Over 22,000 [packages on CRAN](https://cran.r-project.org/web/packages/index.html) -- extensive statistical capabilities
- Integration with other modern tools: Python, HTML, Javascript, Excel, AJAX...
- **Meets modern academic standards of reproducibility and increasingly preferred by statisticians**

![RStudio IDE. Source: Januar Harianto](images/rstudio.png){fig-align="left"}


## Why statistical programming?

Statistical programming **combines** statistics and computer code to:

1. **Analyse** data quickly and accurately -- especially large datasets
2. **Share** methods and results with others
3. **Automate** complex calculations and visualise results clearly

It's like having a *powerful calculator* that can help us tell stories about our data in a repeatable way.


# Key statistical concepts

## Population vs Sample

::: {.columns}
::: {.column width="50%"}
![](images/sample.jpeg)\
:::

::: {.column width="50%"}
###

**Population**

- All possible observations
- Usually too large to measure
- Example: All trees in a forest

**Sample**

- **Subset of the population**
- What we *actually* measure
- Example: 100 trees we measured

**Most (if not all) statistical analyses are based on samples, not populations.**
:::
:::



## Sampling in statistics

How well does a sample represent the population?

Some thoughts:

- **Sample size**: Larger samples are more likely to represent the population
- **Sampling method**: Random samples are more likely to be representative
- **Population variability**: More variability means larger samples are needed


## Samples will vary

Different samples give different results -- suppose we have a population of **1000 trees** and we randomly sample 6 tree heights. If this is done 3 times, it is likely that the samples will be different:

```{r}
#| echo: true
#| code-fold: true

set.seed(258) 
population <- rnorm(1000, mean = 20, sd = 5)

# create samples
sample1 <- sample(population, size = 6)
sample2 <- sample(population, size = 6)
sample3 <- sample(population, size = 6)
```

```{r}
# show samples
for (i in 1:3) {
   cat(sprintf("Sample %d: ", i), get(paste0("sample", i)), "\n")
}
```

So how do we make sense of these samples?

## Descriptive statistics

We can describe our samples using: 

1. **Measures of central tendency** -- describe the "typical" value
   - mean, median, mode

2. **Measures of spread** -- describe how much the data varies
   - standard deviation, variance (commonly used)
   - range, quartiles, IQR (for unique cases)

3. **Measures of uncertainty** -- describe how confident we are in our estimates
   - standard error 
   - confidence intervals


# Measures of central tendency

mean | median | mode

## Mean -- also known as the *average*

The mean is what most people call the "average":

- Add up all your numbers
- Divide by how many numbers you have

::: {.callout-note}
## Mathematical notation
- Population mean: $\mu = \frac{\sum_{i=1}^{N} x_i}{N}$
- Sample mean: $\bar{x} = \frac{\sum_{i=1}^{n} x_i}{n}$

Where:

- $x_i$ is each individual value
- $N$ is population size
- $n$ is sample size
:::

## Mean in R

We can save a group of numbers in a vector called `scores` in R:

```{r}
#| code-fold: false
#| echo: true
# Our test scores
scores <- c(80, 85, 90, 95)
```

::: fragment
Manual calculations:
```{r}
#| code-fold: false
#| echo: true

# manual calculation
(80 + 85 + 90 + 95) / 4

# Alternative way
sum(scores) / length(scores)
```
:::

::: fragment
We can use the `mean()` function:

```{r}
#| code-fold: false
#| echo: true
mean(scores)
```
:::


## Mean in Excel

::: {.columns}
::: {.column width="40%"}
Excel offers several ways to calculate the mean:

1. **Using AVERAGE function**
   ```
   =AVERAGE(A1:A4)
   ```
   - Type `=AVERAGE(`
   - Select cells with your data
   - Press Enter

2. **Using AutoCalculate**
   - Select your data cells
   - Look at bottom right
   - Average shown automatically
:::

::: {.column width="60%"}
![](images/excel-mean.gif)
:::
:::


## Median -- the middle value

The median is the middle number when your data is in order:

1. First, put your numbers in order
2. Find the middle value
3. If you have an even number of values, take the average of the two middle numbers

::: fragment
Example: House prices ($'000s): 450, 1100, 480, 460, 470, 420, 1400, 450, 470

::: fragment
Order: 450, 450, 420, 460, **470**, 470, 480, 1100, 1400
:::

::: fragment
**How is it useful?**
:::
:::

## Median in R

R does all the ordering and finding the middle for us:

```{r}
#| code-fold: false
#| echo: true
# House prices
prices <- c(450, 1100, 480, 460, 470, 420, 1400, 450, 470)

# Find median
median(prices)
```

::: fragment
Comparing the mean and median:
```{r}
#| code-fold: false
#| echo: true
# Compare with mean
mean(prices)
```
:::

::: fragment
**Which is a better measure for house prices?**
:::

## Median in Excel


Excel provides two main ways to find the median:

1. **Using MEDIAN function**
   ```
   =MEDIAN(A1:A9)
   ```
   - Type `=MEDIAN(`
   - Select your data range
   - Press Enter

2. **Alternative method**
   - Sort your data first (use the Sort functionality in the Data tab)
   - Find middle value(s)
   - If even number of values, average the middle two



## Mode -- most frequent value

::: fragment
The mode is the value that appears most frequently in your data. It's particularly useful for:

- Categorical data (like blood types, eye colors)
- Finding the most common item in a group
- Data that has clear repeated values
:::

::: fragment
Calculating the mode can be tricky, especially if there are multiple modes or no mode at all. This is why the mode is not commonly used in statistics.
:::

::: fragment
### Questions that the mode can answer

- What is the most common blood type in a population?
- What is the most common eye color in a group of people?
:::

## Mode in Excel

::: {.columns}
::: {.column width="50%"}
Excel provides several methods to find the mode:

1. **MODE.SNGL function** (single mode)
   ```
   =MODE.SNGL(A1:A10)
   ```
   - Returns most frequent value
   - Returns #N/A if no repeats

2. **MODE.MULT function** (multiple modes)
   ```
   =MODE.MULT(A1:A10)
   ```
   - Returns array of modes
   - Press Ctrl+Shift+Enter
:::

::: {.column width="50%"}
::: {.callout-tip}
## Alternative Method
If you need to count frequencies:

1. Use COUNTIF function:
   ```
   =COUNTIF(range, value)
   ```
2. Find highest count
3. Match back to original values

This is useful when you need to:

- See all frequencies
- Handle text data
- Find multiple modes
:::
:::
:::

## Calculating the mode in R

There is no built-in function to calculate the mode, so we use the `modeest` package:

```{r}
#| code-fold: false
#| echo: true

if(!require("modeest")) install.packages("modeest")
library(modeest)

df <- c(1, 2, 3, 3, 4, 5, 5, 5, 6)
mlv(df, method = "mfv")  # most frequent value
```

::: fragment
If you were to do it yourself, how would you do it in R? 
:::

::: fragment
::: {.panel-tabset}

## Using frequencies
Use the `table()` function to count frequencies:
```{r}
#| code-fold: false
#| echo: true
freq_table <- table(df) # Count frequencies of each value
# Find which value(s) appear most often
modes <- as.numeric(names(freq_table[freq_table == max(freq_table)]))
modes
```

## Using run-length encoding
Use run-length encoding after sorting:
```{r}
#| code-fold: false
#| echo: true
sorted_df <- sort(df) # Sort the vector first
runs <- rle(sorted_df) # Use run-length encoding to find sequences
modes <- runs$values[runs$lengths == max(runs$lengths)] # Find the value(s) with max length
modes
```

## Using loops
Loop through the vector and count occurrences:
```{r}
#| code-fold: false
#| echo: true
unique_vals <- factor(df) # Create a factor of unique values
counts <- tapply(df, unique_vals, length) # Count occurrences using tapply
modes <- as.numeric(names(counts[counts == max(counts)])) # Find which values have the maximum count
modes
```
:::
:::

::: fragment
**The point is that it doesn't matter how you calculate the mode, as long as you are able to do it.** Also -- if you needed this -- aren't you glad R has a package for it?
:::

# Measures of spread

## A biological example

![[Source: Adobe Stock](https://stock.adobe.com/au) # 85659279](images/seagrass.jpg){fig-align="left"}

Imagine sampling seagrass blade lengths from two different sites in a marine ecosystem, and they have the same mean length of 15.2 cm. Are both sites the same?

::: fragment
- **Site A (Protected Bay)**: 15.2, 15.0, 15.3, 15.1, 15.2 centimetres
- **Site B (Wave-exposed Coast)**: 12.0, 18.0, 14.5, 16.5, 15.0 centimetres
:::

## Comparing Different Measures

```{r}
# Plot seagrass lengths
library(ggplot2)
library(patchwork)

seagrass_protected <- c(15.2, 15.0, 15.3, 15.1, 15.2)
seagrass_exposed <- c(12.0, 18.0, 14.5, 16.5, 15.0)

# Create plots for both sites
p1 <- ggplot() +
   geom_point(aes(x = 1:5, y = seagrass_protected), size = 3) +
   geom_hline(yintercept = mean(seagrass_protected), linetype = "dashed", color = "red") +
   labs(title = "Site A: Protected Bay", x = "Measurement", y = "Length (cm)") +
   ylim(10, 20)

p2 <- ggplot() +
   geom_point(aes(x = 1:5, y = seagrass_exposed), size = 3) +
   geom_hline(yintercept = mean(seagrass_exposed), linetype = "dashed", color = "red") +
   labs(title = "Site B: Wave-exposed Coast", x = "Measurement", y = "Length (cm)") +
   ylim(10, 20)

# Combine plots side by side
p1 + p2
```

## Why do we need measures of spread?

- Central tendency (mean, median, mode) only tells part of the story
- Spread tells us how much variation exists in our data
- Different measures of spread tell us different things:
  - **Range**: Overall spread of data
  - **IQR**: Spread of middle 50% of data
  - **Variance**: Average squared deviation from mean
  - **Standard deviation**: Average deviation in original units

## Range -- The simplest measure of spread

```{r}
#| code-fold: false
#| echo: true
# Create our seagrass data
seagrass_protected <- c(15.2, 15.0, 15.3, 15.1, 15.2)  # Protected bay
seagrass_exposed <- c(12.0, 18.0, 14.5, 16.5, 15.0)    # Wave-exposed coast

# Calculate ranges
cat("Protected bay range:", diff(range(seagrass_protected)), "cm\n")
cat("Wave-exposed range:", diff(range(seagrass_exposed)), "cm\n")
```

::: {.callout-note}
The range shows us that seagrass lengths are much more variable in the wave-exposed site!
:::

## Interquartile range (IQR): The middle 50%


The IQR tells us how spread out the middle 50% of our data is:

```{r}
#| code-fold: false
#| echo: true
# Get quartiles for protected bay
quantile(seagrass_protected)
```

- 25% of data below Q1 (1st quartile)
- 75% of data below Q3 (3rd quartile)
- IQR = Q3 - Q1



### Why use IQR?
- Ignores extreme values
- Works with skewed data
- More stable than range


## Comparing Sites Using IQR

```{r}
#| code-fold: false
#| echo: true
# Compare IQRs
pbay <- IQR(seagrass_protected)
pbay
exbay <- IQR(seagrass_exposed)
exbay
```

- Protected bay IQR: `r pbay` cm
- Wave-exposed IQR: `r exbay` cm

::: {.callout-note}
The larger IQR in the wave-exposed site shows more spread in the typical seagrass lengths
:::

## Variance

::: {.columns}
::: {.column width="60%"}
**Why another measure of spread?**

- Range: affected by outliers
- IQR: only uses middle 50%
- We need something that uses *all* the data

**Variance measures:**

- How far each value is from the mean
- In both directions (above and below)
- Squares the differences (makes them positive) -- otherwise the sum is zero
:::

::: {.column width="40%"}
::: {.callout-tip}
## Key Ideas

- Uses every data point
- Squares make big differences count more
- Result is in squared units (cm²)
:::
:::
:::

## Calculating Variance in R

```{r}
#| code-fold: false
#| echo: true
# Calculate variance for both sites
cat("Protected bay variance:", var(seagrass_protected), "cm²\n")
cat("Wave-exposed variance:", var(seagrass_exposed), "cm²\n")
```

::: {.callout-note}
The larger variance in wave-exposed site shows more spread from the mean!
:::

## How Variance Works

::: {.columns}
::: {.column width="60%"}
Let's break it down with the protected bay:

```{r}
#| code-fold: false
#| echo: true
x <- seagrass_protected
# Step 1: Find how far each value is from the mean
diffs <- x - mean(x)
cat("Distance from mean:", round(diffs, 2), "\n")
# Step 2: Square these differences
cat("Squared distances:", round(diffs^2, 2))
```
:::

::: {.column width="40%"}
::: {.callout-tip}
## Steps to Variance
1. Find mean
2. Get distances from mean
3. Square the distances
4. Average the squares
:::
:::
:::

::: {.callout-note}
The `var()` function does all this for us!
:::



## Comparing Spread Measures {.smaller}

| Measure | Protected Bay | Wave-exposed Coast | What it Tells Us |
|---------|:------------:|:-----------------:|------------------|
| Range | `r round(diff(range(seagrass_protected)), 2)` cm | `r round(diff(range(seagrass_exposed)), 2)` cm | Overall spread (sensitive to outliers) |
| IQR | `r round(IQR(seagrass_protected), 2)` cm | `r round(IQR(seagrass_exposed), 2)` cm | Middle 50% spread (ignores extremes) |
| Variance | `r round(var(seagrass_protected), 2)` cm² | `r round(var(seagrass_exposed), 2)` cm² | Average squared distance from mean |

### Key Observations
- Wave-exposed site shows consistently more variation
- Each measure gives a different perspective
- Choose based on your data and goals


## Standard deviation: Back to original units

Standard deviation is the square root of variance, giving us a measure of spread in the original units (cm instead of cm²):

```{r}
#| code-fold: false
#| echo: true
# Calculate standard deviation for both sites
cat("Protected bay SD:", sd(seagrass_protected), "cm\n")
cat("Wave-exposed SD:", sd(seagrass_exposed), "cm\n")
```

::: {.callout-note}
## For those interested in the math
Standard deviation ($s$) is: $s = \sqrt{\frac{\sum_{i=1}^{n} (x_i - \bar{x})^2}{n-1}}$
:::

## Interpreting Standard Deviation

We can describe our seagrass lengths using mean ± standard deviation:

```{r}
#| code-fold: false
#| echo: true
# Protected bay
mean_p <- mean(seagrass_protected)
sd_p <- sd(seagrass_protected)
cat("Protected bay:", round(mean_p, 1), "±", round(sd_p, 2), "cm\n")

# Wave-exposed
mean_e <- mean(seagrass_exposed)
sd_e <- sd(seagrass_exposed)
cat("Wave-exposed:", round(mean_e, 1), "±", round(sd_e, 2), "cm\n")
```

::: {.callout-tip}
The ± tells us about the typical variation around the mean. Larger values indicate more spread!
:::

# Debugging in R: Your problem-solving toolkit

::: {.callout-note}
## Remember: Everyone Faces Errors!
Debugging is a normal part of programming. Even experienced programmers spend a lot of time debugging. It's not about avoiding errors - it's about learning how to fix them!
:::

## What is debugging?

::: {.columns}
::: {.column width="60%"}
- Process of finding and fixing errors in your code
- Essential skill for statistical programming
- Makes you a better programmer
- Helps you understand how R works
:::

::: {.column width="40%"}
::: {.callout-tip}
## Debugging Mindset
- Stay calm - errors help you learn
- Break problems into small steps
- Take breaks if frustrated
- Celebrate when you fix errors!
:::
:::
:::

::: {.callout-note}
## Fun fact
The term "bug" comes from a moth found in an early computer in 1947! This shows that problems in computers have been around since the beginning - you're not alone in facing them.
:::

## Common Student Challenges

1. **Starting R for the first time**
   ```r
   # Error: could not find function
   # Don't panic! You probably need to:
   library(packagename)  # Load the package first
   ```

2. **Copy-paste issues**
   ```r
   # Error: unexpected symbol
   # Check for hidden characters or
   # incorrect quote marks (" vs ")
   ```

3. **Case sensitivity confusion**
   ```r
   # These are different!
   myData <- c(1,2,3)
   print(mydata)  # Error: object 'mydata' not found
   ```

::: {.callout-warning}
## When You're Stuck
1. Read the error message carefully
2. Check for typos
3. Verify package is loaded
4. Ask for help - we're here to support you!
:::

## Understanding R's Messages

::: {.callout-note}
## Think of R Messages as Helpful Feedback
R tries to communicate with you in different ways. Learning to interpret these messages will make you a more confident R user!
:::

R has three types of friendly messages:

1. **Messages** (Information) 💬
   ```r
   library(ggplot2)
   #> Loading required package: ggplot2
   ```
   - Just keeping you informed
   - Like a friendly "FYI"
   - No action needed
   - Common examples:
     * Package loading messages
     * Progress updates
     * Information about operations

2. **Warnings** (Potential issues) ⚠️
   ```r
   mean(c(1, 2, NA, 4))
   #> Warning: NAs present, result might be unexpected
   ```
   - Code still runs but needs attention
   - Like a "heads up" from R
   - Good to investigate why
   - Common examples:
     * Missing values in calculations
     * Data type conversions
     * Deprecated function usage

3. **Errors** (Code cannot run) 🛑
   ```r
   sum("apple")
   #> Error: invalid 'type' (character) of argument
   ```
   - Must fix before continuing
   - Think of these as learning opportunities
   - Usually have clear solutions
   - Common examples:
     * Syntax mistakes
     * Missing packages
     * Wrong data types

::: {.callout-tip}
## Message Handling Strategy
1. Stay calm - messages are R's way of helping
2. Read the message carefully
3. Look for keywords that hint at the problem
4. If stuck, use the message text to search for help
:::

## Common Error Types in R

### Syntax Errors
```{r}
#| code-fold: false
#| error: true
#| warning: true
mean(x = c(1,2,3))   
mean(x = c(1,2,3,))  
```

### Object Not Found
```{r}
#| code-fold: false
#| error: true
#| warning: true
# Trying to use data before creating it
plot(my_data)
```

## More Common Errors

### Type Mismatches
```{r}
#| code-fold: false
#| error: true
#| warning: true
# Mixing numbers and text
sum(c(1, 2, "three"))
```

### Package Not Installed
```{r}
#| code-fold: false
#| error: true
#| warning: true
# Trying to use function without loading package
ggplot(data = mtcars)
```

## Understanding Warning Messages

### Example 1: Missing Values
```{r}
#| code-fold: false
#| error: true
#| warning: true
mean(c(1, 2, NA, 4))
```

### Example 2: Data Coercion
```{r}
#| code-fold: false
#| error: true
#| warning: true
# Mixing data types
as.numeric(c("1", "2", "three"))
```

## RStudio Debugging Tools

Key features in RStudio for debugging:

1. **Environment tab**
   - View all objects
   - Check data structures

2. **Console messages**
   - Red text = Errors
   - Orange text = Warnings

3. **Traceback**
   - Shows error location
   - Press 'Show Traceback'

## Interactive Debugging

Useful functions for debugging:

```{r}
#| code-fold: false
#| eval: false
str(data)      # Examine structure
head(data)     # View first rows
class(data)    # Check data type
typeof(data)   # Check storage type
```

## Debugging Workflow

1. **Identify the problem**
   - Read error message carefully
   - Check which line caused error
   - Examine data structure

2. **Isolate the issue**
   - Run code line by line
   - Print intermediate results
   - Check object types

3. **Test solutions**
   - Try with simple examples
   - Verify data types match
   - Check documentation

## Modern Debugging Resources

1. **Online Communities**
   - Stack Overflow
   - RStudio Community
   - R-bloggers

2. **AI Assistants**
   - GitHub Copilot
   - ChatGPT
   - Claude

3. **R Documentation**
   - `?function_name`
   - Package vignettes
   - CRAN documentation

