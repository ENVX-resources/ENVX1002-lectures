---
title: Topic 11 -- Multiple Linear Regression
subtitle: ENVX1002 Introduction to Statistical Methods
author: Liana Pozza
institute: The University of Sydney
date: last-modified # today | last-modified
date-format: "MMM YYYY" # see https://momentjs.com/docs/#/displaying/format/
format: soles-revealjs
---

```{r setup, include=FALSE}
if (!require("pacman")) install.packages("pacman", repos = "http://cran.us.r-project.org")
pacman::p_load(tidyverse, cowplot, HistData, datasauRus, patchwork, broom, remotes, corrplot, psych, plotly)
pacman::p_load_gh("datalorax/equatiomatic")

ggplot2::theme_set(cowplot::theme_half_open())
```




## Module overview

- **Week 9. Describing relationships**
    + Correlation &rarr; calculation, interpretation, things to watch out for
    + Regression &rarr; Why do we care? model structure, model fitting
  
- **Week 10. Linear functions**
    + Is the model worth fitting? &rarr; Assumptions, hypothesis testing
    + How good is the model? &rarr; Measures of model fit
  
- **Week 11. Linear functions - multiple predictors** 
    + Parsimonious models
    + Introduction to Multiple Linear Regression (MLR) modelling
    + Assumptions and interpretation

- **Week 12. Nonlinear functions**
    + Common nonlinear functions
    + Transformations
    + Performing nonlinear regression


## Module overview
  
- **Week 11. Linear functions - multiple predictors** 
    + Parsimonious models
    + Introduction to Multiple Linear Regression (MLR) modelling
    + Assumptions and interpretation






# Recap

## Simple linear regression

$$ Y_i = \beta_0 + \beta_1 x_i + \epsilon_i $$

  Ideal for predicting a continuous response variable from a single predictor variable: *"How does $y$ change as $x$ changes?"*

. . .

### What if we have more than one predictor?

What is the model and how do we interpret the results?


# Multiple linear regression

![Galton](images/galton.jpg)
![Pearson](images/pearson.jpg)

*Francis Galton and Karl Pearson*

## History

- First raised by **Francis Galton** in 1886, after studying genetic variations in sweet peas over several generations.
- **Karl Pearson** developed the mathematical formalism for the multiple linear regression model in the early 1900s.

> *“The somewhat complicated mathematics of multiple correlation, with its repeated appeals to the geometrical notions of hyperspace, remained a closed chamber to him.”*

-- Pearson (1930), on Galton's work with MLR

# Air Quality in New York (1973)


## Air quality {auto-animate="true"}




```{r}
data(airquality)
dplyr::glimpse(airquality)
```



## {auto-animate="true"}



```{r}
#| echo: false
dplyr::glimpse(airquality)
```



. . .

Ozone: harmful air pollutant when present at ground level; main component of smog:

- `Ozone`: ozone concentration (ppb)
- `Solar.R`: solar radiation (lang)
- `Wind`: wind speed (mph)
- `Temp`: ambient temperature (degrees F)
- `Month`: month (1-12)
- `Day`: day of the month (1-31)

## Correlations



```{r}
pairs(airquality)
```




## `corrplot`



```{r}
library(corrplot)
corrplot::corrplot(cor(airquality, use = "complete.obs"), method = "circle")
```




## `psych`



```{r}
psych::pairs.panels(airquality)
```



## The simplest model {auto-animate="true"} 

Pick the predictor that has the highest correlation coefficient with the response variable.

:::{.fragment}


```{r}
cor(airquality, use = "complete.obs")
```


:::

:::{.fragment}
What can we understand about the relationship between `Ozone` and `Temp` ($r$ = 0.7)?
:::

## Relationship {auto-animate="true"} 
What can we understand about the relationship between `Ozone` and `Temp` ($r$ = 0.7)?

. . .



```{r}
ggplot(data = airquality, aes(x = Temp, y = Ozone)) +
  geom_point() +
  labs(x = expression("Temperature " ( degree~F)), y = "Ozone (ppb)")
```



## Relationship
What can we understand about the relationship between `Ozone` and `Temp` ($r$ = 0.7)?



```{r}
ggplot(data = airquality, aes(x = Temp, y = Ozone)) +
  geom_point() + geom_smooth(method = "lm", se = FALSE) +
  labs(x = expression("Temperature " ( degree~F)), y = "Ozone (ppb)")
```



## Fitting the model



```{r}
fit <- lm(formula = Ozone ~ Temp, data = airquality)
```



## Assumptions



```{r}
par(mfrow = c(2, 2)) # set up a 2 x 2 grid for plots
plot(fit)
```




## `ggfortify`



```{r}
library(ggfortify)
autoplot(fit)
```



## Interpretation



```{r}
summary(fit)
```



- `Temp` is a statistically significant predictor of `Ozone` (p < .001).
- The (simple linear) model explains 49% of variance (r^2^ = 0.49).

. . .

**Can we improve the model in other ways?**

# Multiple linear regression

## Important concepts

- The "best" model is the one that best describes the relationship between the response and the predictors. 
  - **NOT** the model that includes all possible predictors ([data dredging](https://en.wikipedia.org/wiki/Data_dredging)).

. . .

### Principle of parsimony
A good model:

- Has only *useful* predictors.
- Has no *redundant* predictors (principle of orthogonality).
- Is *interpretable* (principle of transparency) or *predicts well* (principle of accuracy).


## The MLR model {auto-animate="true"}

An extension of simple linear regression to include **more than one** predictor variable: *"How does $y$ change as $x_1$, $x_2$, ..., $x_k$ change?"*

$$ Y_i = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_k x_k + \epsilon_i $$

:::{.fragment}
Therefore, estimating the model involves *estimating the values of* $\beta_0$, $\beta_1$, $\beta_2$, ..., $\beta_k$.

- $\beta_0$ is the intercept
- $\beta_1$ to $\beta_k$ are the partial regression coefficients
- $\epsilon$ is the error term
:::


## Explore



```{r}
glimpse(airquality)
```



<br>

:::{.fragment}
### The "best" model

The variables `Month` and `Day` are not useful predictors, so we will exclude them from the model.



```{r}
fit_multi <- lm(formula = Ozone ~ Solar.R + Wind + Temp, data = airquality)
```


:::

## Visualisation: not easy

Are the plots useful?

### 3D plot



```{r}
library(plotly)
plot_ly(data = airquality, 
  x = ~Temp, y = ~Ozone, z = ~Solar.R,
  type = "scatter3d", mode = "markers", opacity = 0.5)
```



## Visualisation: not easy

Are the plots useful?

### 4D plot



```{r}
library(plotly)
plot_ly(data = airquality, 
  x = ~Temp, y = ~Ozone, z = ~Solar.R, color = ~Wind,
  type = "scatter3d", mode = "markers", opacity = 0.5)
```




## Partial regression coefficients {auto-animate="true"}

Given the multiple linear model:
$$ Y_i = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_k x_k + \epsilon_i $$


The partial regression coefficient for a predictor $x_i$ is the amount by which the response variable $Y$ changes when $x_k$ is increased by one unit, **while all other predictors are held constant**.

$$ \beta_k = \frac{\Delta Y}{\Delta x_k} $$

. . .




```{r}
equatiomatic::extract_eq(fit_multi)
```



> *With `Wind` and `Solar.R` held constant, how does `Temp` affect `Ozone`?*

## Partial regression coefficients: visualisation {auto-animate="true"}



```{r}
sjPlot::plot_model(fit_multi,
  type = "pred", 
  terms = c("Temp", "Solar.R", "Wind"), 
  ci.lvl = NA)
```



> *With `Wind` and `Solar.R` held constant, how does `Temp` affect `Ozone`?*

## Interpreting the partial regression coefficients



```{r}
fit_multi
```




:::{.fragment}
Holding **all** other variables constant:

- For every 1 unit increase in `Solar.R`, `Ozone` increases by a mean value of 0.06 ppb.
- For every 1 degree increase in `Temp`, `Ozone` increases by a mean value of 1.65 ppb.
- For every 1 unit increase in `Wind`, `Ozone` decreases by a mean value of 3.33 ppb.
:::

:::{.fragment}
:::{.callout-caution}
If the model is not "valid", then the partial regression coefficients are not meaningful.
:::
:::

# Assumptions

## LINE

As with Simple Linear Regression, we need to check the assumptions of the model (LINE):

- **L**inearity: the relationships between the response and the predictors are all linear.
- **I**ndependence: the observations are independent of each other.
- **N**ormality: the residuals are normally distributed.
- **E**qual variance: the variance of the residuals is constant.

## Recall

In SLR, the model is made up of the [**deterministic**]{style="color:seagreen"} component (the line) and the [***random***]{style="color:firebrick"}  component (the error term).

$$ Y_i = \color{seagreen}{\beta_0 + \beta_1 x_i} + \color{firebrick}\epsilon_i $$

. . .

**This is the same for MLR:**
$$ Y_i = \color{seagreen}{\beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_k x_k} + \color{firebrick}{\epsilon_i} $$

Since *only* the error term is random, the assumptions are *still* about the error term, $\hat\epsilon$, which is simple to assess!

## Assumptions of MLR



```{r}
par(mfrow = c(2, 2)) # set up a 2 x 2 grid for plots
plot(fit_multi)
```



## Transformation using `log()`

Some evidence of nonlinearity in the diagnostic plots. Transform and re-check assumptions.

. . .



```{r}
fit_multi_log <- lm(formula = log(Ozone) ~ Solar.R + Wind + Temp, data = airquality)
par(mfrow = c(2, 2)) # set up a 2 x 2 grid for plots
plot(fit_multi_log)
```



## Results 
:::: {.columns}
::: {.column width="50%"}


```{r}
summary(fit_multi_log)
```


:::
::: {.column width="50%"}
:::
::::

- All three predictors are statistically significant (p < .001).
- The model explains 66% of variance (r^2^ = 0.66).

## Results compared to SLR

:::: {.columns}
::: {.column width="50%"}


```{r}
summary(fit_multi_log)
```


:::
::: {.column width="50%"}


```{r}
summary(fit)
```


:::
::::

- All three predictors are statistically significant (p < .001).
- The model explains 66% of variance (r^2^ = 0.66 vs. 0.48 in SLR). 

# Interpretation

## Coefficients


```{r}
#| eval: false
#| code-line-numbers: 8-13

Call:
lm(formula = log(Ozone) ~ Solar.R + Wind + Temp, data = airquality)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.06193 -0.29970 -0.00231  0.30756  1.23578 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.2621323  0.5535669  -0.474 0.636798    
Solar.R      0.0025152  0.0005567   4.518 1.62e-05 ***
Wind        -0.0615625  0.0157130  -3.918 0.000158 ***
Temp         0.0491711  0.0060875   8.077 1.07e-12 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.5086 on 107 degrees of freedom
  (42 observations deleted due to missingness)
Multiple R-squared:  0.6644,    Adjusted R-squared:  0.655 
F-statistic: 70.62 on 3 and 107 DF,  p-value: < 2.2e-16
```



All three predictors are statistically significant (p < .001).

- For every 1 unit increase in `Solar.R`, `log(Ozone)` increases by a mean value of 0.0025 ppb, holding all other variables constant.
- For every 1 unit increase in `Wind`, `log(Ozone)` decreases by a mean value of 0.062 ppb, holding all other variables constant.
- For every 1 degree increase in `Temp`, `log(Ozone)` increases by a mean value of 0.049 ppb, holding all other variables constant.


## Residual standard error



```{r}
#| eval: false
#| code-line-numbers: 17-17

Call:
lm(formula = log(Ozone) ~ Solar.R + Wind + Temp, data = airquality)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.06193 -0.29970 -0.00231  0.30756  1.23578 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.2621323  0.5535669  -0.474 0.636798    
Solar.R      0.0025152  0.0005567   4.518 1.62e-05 ***
Wind        -0.0615625  0.0157130  -3.918 0.000158 ***
Temp         0.0491711  0.0060875   8.077 1.07e-12 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.5086 on 107 degrees of freedom
  (42 observations deleted due to missingness)
Multiple R-squared:  0.6644,    Adjusted R-squared:  0.655 
F-statistic: 70.62 on 3 and 107 DF,  p-value: < 2.2e-16
```



::: {.fragment .fade-out}
On average, the model predicts `log(Ozone)` within 0.51 ppb of the true value. *Not bad?*
:::

. . .



```{r}
exp(0.51)
```



- On average, the model predicts `Ozone` within `r exp(0.51)` ppb of the true value.
- Number of observations = degrees of freedom (107) + number of parameters in the model (4) = 111.

## R-squared



```{r}
#| eval: false
#| code-line-numbers: 19-19

Call:
lm(formula = log(Ozone) ~ Solar.R + Wind + Temp, data = airquality)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.06193 -0.29970 -0.00231  0.30756  1.23578 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.2621323  0.5535669  -0.474 0.636798    
Solar.R      0.0025152  0.0005567   4.518 1.62e-05 ***
Wind        -0.0615625  0.0157130  -3.918 0.000158 ***
Temp         0.0491711  0.0060875   8.077 1.07e-12 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.5086 on 107 degrees of freedom
  (42 observations deleted due to missingness)
Multiple R-squared:  0.6644,    Adjusted R-squared:  0.655 
F-statistic: 70.62 on 3 and 107 DF,  p-value: < 2.2e-16
```



If there are >1 predictors, use the **Adjusted R-Squared** as it penalises the model for having more predictors that are not useful.

## F-stat



```{r}
#| eval: false
#| code-line-numbers: 20-20

Call:
lm(formula = log(Ozone) ~ Solar.R + Wind + Temp, data = airquality)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.06193 -0.29970 -0.00231  0.30756  1.23578 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.2621323  0.5535669  -0.474 0.636798    
Solar.R      0.0025152  0.0005567   4.518 1.62e-05 ***
Wind        -0.0615625  0.0157130  -3.918 0.000158 ***
Temp         0.0491711  0.0060875   8.077 1.07e-12 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.5086 on 107 degrees of freedom
  (42 observations deleted due to missingness)
Multiple R-squared:  0.6644,    Adjusted R-squared:  0.655 
F-statistic: 70.62 on 3 and 107 DF,  p-value: < 2.2e-16
```



- The F-statistic tests the null hypothesis that all the regression coefficients are equal to zero, i.e. $H_0: \beta_1 = \beta_2 = ... = \beta_k = 0$.
- As a ratio, it tells us how much better the model is than the null model (i.e. a model with no predictors).
- If the p-value is less than our specified critical value (e.g. 0.05), we reject the null hypothesis and conclude that the current model is better than the null model.

## Reporting



```{r}
#| eval: false

Call:
lm(formula = log(Ozone) ~ Solar.R + Wind + Temp, data = airquality)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.06193 -0.29970 -0.00231  0.30756  1.23578 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.2621323  0.5535669  -0.474 0.636798    
Solar.R      0.0025152  0.0005567   4.518 1.62e-05 ***
Wind        -0.0615625  0.0157130  -3.918 0.000158 ***
Temp         0.0491711  0.0060875   8.077 1.07e-12 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.5086 on 107 degrees of freedom
  (42 observations deleted due to missingness)
Multiple R-squared:  0.6644,    Adjusted R-squared:  0.655 
F-statistic: 70.62 on 3 and 107 DF,  p-value: < 2.2e-16
```



Solar radiation, wind speed and temperature are **significant predictors** of Ozone concentration (**p < 0.001**) with the model accounting for **66% of the variation** in weight.


# Abalone: full example



## Data

Data from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/abalone).



```{r}
abalone <- read_csv("data/abalone.csv")
glimpse(abalone)
```



## Preview



```{r}
#| fig.width: 10
#| fig.height: 8
#| out.width: 100%
#| out.height: 700px
psych::pairs.panels(abalone)
```



# Live coding session

Data import → EDA → Model fitting → Diagnostics → Transform/Select → Interpret

*Let's fit a model to predict the whole weight of abalone from other measured variables -- I will now switch to RStudio.*

# And we're back!

A quick recap on sub-sampling the dataset:



```{r}
set.seed(1113)
abalone <- 
  abalone %>%
  select(-sex) %>%
  sample_n(100)
```



## What we did

- Fitted a model to predict the whole weight of abalone from other measured variables.
- Performed a transformation of the response variable to improve model fit.
- Checked the assumptions of the model.
- Interpreted the model coefficients.
- Interpreted the model fit.


# Model complexity: overfitting
> Why can't we just use ALL the predictors?

## The problem with using too many predictors

- The more predictors you add, the better the model fits the data.
- However, the model may not be able to **generalise** to new data: **overfitting**.



```{r}
#| code-fold: true
# abalone <-
#   abalone %>%
#   select(-sex)

library(broom)

full7 <- lm(sqrt(whole) ~ ., data = abalone)
part6 <- update(full7, . ~ . - diameter)
part5 <- update(part6, . ~ . - viscera)
part4 <- update(part5, . ~ . - rings)
part3 <- update(part4, . ~ . - length)
part2 <- update(part3, . ~ . - height)
part1 <- update(part2, . ~ . - shell)

formulas <- c(part1$call$formula, 
              part2$call$formula, 
              part3$call$formula, 
              part4$call$formula, 
              part5$call$formula, 
              part6$call$formula, 
              full7$call$formula)

rs <- bind_rows(glance(part1),
                glance(part2),
                glance(part3),
                glance(part4),
                glance(part5),
                glance(part6),
                glance(full7)) %>%
  mutate(Model = formulas) %>%
  select(Model, r.squared, adj.r.squared) %>%
  mutate_if(is.numeric, round, 3)

knitr::kable(rs)
```



## The r^2^ value

The R-squared value is the proportion of variance explained by the model.

$$ r^2 = \frac{SS_{reg}}{SS_{tot}} = 1 - \frac{SS_{res}}{SS_{tot}} $$

The adjusted R-squared value is the proportion of variance explained by the model, adjusted for the number of predictors.

$$ r^2_{adj} = 1 - \frac{SS_{res}}{SS_{tot}} \frac{n-1}{n-p-1} $$

where $n$ is the number of observations and $p$ is the number of predictors.




## Full model vs reduced model

::::{.columns}
:::{.column width="50%"}


```{r}
#| height: 500px
full <- lm(sqrt(whole) ~ ., data = abalone)
summary(full)
```



:::
:::{.column width="50%"}


```{r}
#| height: 300px
reduced <- lm(sqrt(whole) ~ shell + height + diameter, data = abalone)
summary(reduced)
```


:::
::::

<br>

- Is the 0.015 improvement in the adjusted R-squared -- *an extra 1.5% of the variance explained* -- worth the extra predictors? 
- Recall: **principle of parsimony** - the simplest model that explains the data is the best.
- But how do we know which predictors to keep?

## Model selection

- Covered in **second year (ENVX2001)**.
- Using techniques of **stepwise regression**, we can select the best model from a set of "candidate" models.
- If we have non-significant predictors, we can consider the effect of removing them from the model (**partial F-test**).
- Aim is to achieve the best balance between **model fit** and **model complexity**.

## Summary

- MLR is an extension of SLR to include more than one predictor.
  - Instead of a line, we are fitting a "hyperplane" i.e. multiple dimensions.
  - However, the principles are the same: we are still trying to minimise the sum of squared residuals.
  - Assumptions of MLR are the same as SLR.
  - Instead of the multiple R-squared value, we use the adjusted R-squared value to assess model fit.

. . .

- Follow the rules of parsimony: the simplest model that explains the data is the best, given similar model fit.
  - Consider the effect of removing non-significant predictors from the model.



# Thanks!

This presentation is based on the [SOLES Quarto reveal.js template](https://github.com/usyd-soles-edu/soles-revealjs) and is licensed under a [Creative Commons Attribution 4.0 International License][cc-by].


<!-- Links -->
[cc-by]: http://creativecommons.org/licenses/by/4.0/
