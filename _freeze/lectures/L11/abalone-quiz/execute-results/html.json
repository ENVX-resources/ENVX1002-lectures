{
  "hash": "e742e9f6713a1d232239c0e0f4bbc50d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"L11 MLR -- Abalone Quiz\"\nauthor: Si Yang Han\nformat: soles-revealjs\nembed-resources: true\n---\n\n\n\n\n\n\n\n\n# Abalone Quiz\n\n![](images/abalone.jpg)\n\n> Pop quiz! (No marks, just check your understanding. It's...tricky.)\n\n> This dataset records abalone from the coast of Tasmania, Australia (Nash, 1995) and was accessed from the [UCI Machine Learning Repository]<https://archive.ics.uci.edu/dataset/1/abalone>.\n\n## Introduction\n\nAbalone are marine snails that are a considered a delicacy and very expensive. The older the abalone, the higher the price. Age is determined by counting the number of rings in the shell. To do this, the shell needs to be cut, stained and viewed under a microscope - which is a lot of effort. Researchers measured 9 attributes of the abalone: `sex`, `length`, `diameter`, `height`, `whole`, `shucked`, `viscera`, `shell`, and `rings`.\n\nNote: `whole`, `shucked`, `viscera` and `shell` are weight measurements.\n\n. . .\n\n**What is the response variable?**\n\na) length\nb) rings\nc) shell (weight)\nc) whole (weight)\n\n. . .\n\n> Reading comprehension :)\n\n## Research question {auto-animate=\"true\"} \n\nAbalone are marine snails that are a considered a delicacy and very expensive. The older the abalone, the higher the price. Age is determined by counting the number of rings in the shell. To do this, the shell needs to be cut, stained and viewed under a microscope - which is a lot of effort. Researchers measured 9 attributes of the abalone: `sex`, `length`, `diameter`, `height`, `whole`, `shucked`, `viscera`, `shell`, and `rings`.\n\nNote: `whole`, `shucked`, `viscera` and `shell` are weight measurements.\n\n**What is the best research question, based on the context above?**\n\na) Is there a correlation between abalone age and weight?\nb) Can abalone weight be predicted from other measured variables?\nc) Is there a relationship between abalone size and age?\nd) Can age be measured by size?\n\n. . .\n\n> A is not a complete answer, there are many more predictors. B is incorrect, we care about age/rings. D is incorrect, we are trying to *model or predict abalone age from size* -- terminology matters.\n\n## Explore data {auto-animate=\"true\"}\n\nWe sample the data to make it easier to visualise relationships. We also remove the `sex` variable because it is not numeric.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nabalone <- read.csv(\"data/abalone.csv\")\n\nset.seed(1113)          # reproducible randomness\nabalone <- abalone %>% \n  select(-sex) %>%      # remove `sex` because it is categorical\n  sample_n(100)         # sample 100 observations for cleaner curve\n  \nstr(abalone)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t100 obs. of  8 variables:\n $ length  : num  0.52 0.71 0.33 0.67 0.65 0.35 0.695 0.52 0.6 0.61 ...\n $ diameter: num  0.405 0.57 0.255 0.55 0.51 0.25 0.53 0.41 0.475 0.48 ...\n $ height  : num  0.14 0.195 0.095 0.17 0.19 0.1 0.15 0.14 0.15 0.17 ...\n $ whole   : num  0.692 1.348 0.188 1.247 1.542 ...\n $ shucked : num  0.276 0.8985 0.0735 0.472 0.7155 ...\n $ viscera : num  0.137 0.444 0.045 0.245 0.373 ...\n $ shell   : num  0.215 0.454 0.06 0.4 0.375 ...\n $ rings   : int  11 11 7 21 9 7 14 11 10 10 ...\n```\n\n\n:::\n:::\n\n\n\n\n\n\n---\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npsych::pairs.panels(abalone)     # visualise relationships\n```\n\n::: {.cell-output-display}\n![](abalone-quiz_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n:::{.columns}\n:::{.column width=\"70%\"}\n\n**What is the most correlated predictor with (number of) abalone rings?**\n\na) age  \nb) length  \nc) whole (weight)  \nd) shell (weight)\n\n:::\n\n:::{.column width=\"30%\"}\n\n:::{.fragment .fade-in}\n> Age is a trick - it is not a predictor! The answer is **`shell` (weight)**.\n\n:::\n\n:::\n:::\n\n---\n\n:::{.columns}\n:::{.column width=\"60%\"}\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(abalone, aes(x = rings, y = shell)) +\n  geom_point(size = 3) +\n  labs(x = \"Rings\", y = \"Shell (weight)\") +\n  theme(text = element_text(size = 16))\n```\n\n::: {.cell-output-display}\n![](abalone-quiz_files/figure-html/unnamed-chunk-3-1.png){width=768}\n:::\n\n```{.r .cell-code}\ncor(abalone) |> round(2) |> print() # visualise relationships\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         length diameter height whole shucked viscera shell rings\nlength     1.00     0.99   0.88  0.93    0.90    0.90  0.90  0.50\ndiameter   0.99     1.00   0.89  0.93    0.91    0.90  0.92  0.53\nheight     0.88     0.89   1.00  0.89    0.85    0.85  0.89  0.54\nwhole      0.93     0.93   0.89  1.00    0.96    0.94  0.95  0.50\nshucked    0.90     0.91   0.85  0.96    1.00    0.92  0.88  0.36\nviscera    0.90     0.90   0.85  0.94    0.92    1.00  0.89  0.42\nshell      0.90     0.92   0.89  0.95    0.88    0.89  1.00  0.63\nrings      0.50     0.53   0.54  0.50    0.36    0.42  0.63  1.00\n```\n\n\n:::\n:::\n\n\n\n\n\n\n:::\n:::{.column width=\"40%\"}\n\n**Which assumption/s do we need to be wary of?**\n\na) linearity\nb) collinearity\nc) equal variances\nd) all of the above\n\n:::{.fragment .fade-in}\n> In the `ring` plot, the relationship is not clearly linear and there is fanning (unlikely equal variances met). There is also very high correlation between some predictors (e.g. `length` and `diameter`), so the answer is D.\n\n:::\n\n:::\n:::\n\n## Fit a model {auto-animate=\"true\"}\n\n:::{.columns}\n:::{.column width=\"50%\"}\nWe use natural log transformation on the response variable with `log()` to account for non-linear relationships.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- lm(log(rings) ~ ., data = abalone)\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log(rings) ~ ., data = abalone)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.37297 -0.12727 -0.01584  0.08787  0.61636 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.34626    0.18219   7.389 6.57e-11 ***\nlength      -1.25389    1.50969  -0.831  0.40837    \ndiameter     3.24138    1.91481   1.693  0.09388 .  \nheight       2.26408    1.34813   1.679  0.09646 .  \nwhole        0.03089    0.29250   0.106  0.91612    \nshucked     -1.30902    0.38861  -3.368  0.00111 ** \nviscera     -0.24785    0.55098  -0.450  0.65389    \nshell        1.73328    0.60179   2.880  0.00494 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1996 on 92 degrees of freedom\nMultiple R-squared:  0.6187,\tAdjusted R-squared:  0.5897 \nF-statistic: 21.32 on 7 and 92 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n\n\n:::\n:::{.column width=\"50%\"}\n\n**Which predictor is NOT significant to the model?**\n\na) height\nb) whole (weight)\nc) shucked (weight)\nd) viscera (weight)\n\n:::{.fragment .fade-in}\n> Whole (weight) has a period (.) beside the p-value -- this means the value is less than 0.10, but it needs to be <0.05 to be considered significant.\n\n:::\n\n:::\n:::\n\n\n## Fit a model\n\n```r\nResidual standard error: 0.1996 on 92 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.5897 \nF-statistic: 21.32 on 7 and 92 DF,  p-value: < 2.2e-16\n```\n\n**We determine model fit with:**\n\na) Multiple R-squared and p-value\nb) Adjusted R-squared and p-value\nc) Adjusted R-squared and residual standard error\nd) Multiple R-squared and residual standard error\n\n. . .\n\n> We have multiple variables, so we use the Adjusted R-squared. The p-value tests the hypothesis on whether the model should be used at all, in favour of the mean. The residual error is a measure of model fit.\n\n## The problem with using too many predictors\n\nHere, the model is fit with all predictors, then the least significant predictor is removed. This process is repeated until only one predictor remains.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(broom)\n\nfull7 <- lm(log(rings) ~ ., data = abalone)\npart6 <- update(full7, . ~ . - whole)\npart5 <- update(part6, . ~ . - viscera)\npart4 <- update(part5, . ~ . - length)\npart3 <- update(part4, . ~ . - height)\npart2 <- update(part3, . ~ . - diameter)\npart1 <- update(part2, . ~ . - shucked)\n\nformulas <- c(part1$call$formula, \n              part2$call$formula, \n              part3$call$formula, \n              part4$call$formula, \n              part5$call$formula, \n              part6$call$formula, \n              full7$call$formula)\n\nrs <- bind_rows(glance(part1),\n                glance(part2),\n                glance(part3),\n                glance(part4),\n                glance(part5),\n                glance(part6),\n                glance(full7)) %>%\n  mutate(Model = formulas, n = 1:7) %>%\n  select(Model, n, r.squared, adj.r.squared) %>%\n  mutate_if(is.numeric, round, 3)\n\nknitr::kable(rs)\n```\n\n::: {.cell-output-display}\n\n\n|Model                                                                     |  n| r.squared| adj.r.squared|\n|:-------------------------------------------------------------------------|--:|---------:|-------------:|\n|log(rings) ~ shell                                                        |  1|     0.445|         0.439|\n|log(rings) ~ shucked + shell                                              |  2|     0.557|         0.548|\n|log(rings) ~ diameter + shucked + shell                                   |  3|     0.604|         0.591|\n|log(rings) ~ diameter + height + shucked + shell                          |  4|     0.614|         0.598|\n|log(rings) ~ length + diameter + height + shucked + shell                 |  5|     0.618|         0.597|\n|log(rings) ~ length + diameter + height + shucked + viscera + ,     shell |  6|     0.619|         0.594|\n|log(rings) ~ .                                                            |  7|     0.619|         0.590|\n\n\n:::\n:::\n\n\n\n\n\n\n::: {.columns}\n:::{.column width=\"40%\"}\n\n**Considering only $R^2$, which model would we choose?**\n\na) Model with 1 predictor\nb) Model with 3 predictors\nc) Model with 4 predictors\nd) Model with 7 predictors\n:::\n:::{.column width=\"60%\"}\n:::{.fragment .fade-in}\n\n> The 1-predictor model sacrifices 14.5% of variation in the response (too much). The 7-predictor model is overfitted (worse than 4-predictor model). Between 3 and 4-predictor models - is a 0.7% improvement worth having to measure `height`? Realistically, the models with 2 or 3 predictors are justifiable.\n\n:::\n\n:::\n:::\n\n## Interpretation\n\n```r\n#| eval: false\nCall:\nlm(formula = log(rings) ~ diameter + shucked + shell, data = abalone)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.30290 -0.15469 -0.03485  0.11454  0.64573 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   1.4122     0.1594   8.859 4.19e-14 ***\ndiameter      2.0346     0.6034   3.372  0.00108 ** \nshucked      -1.3339     0.2152  -6.200 1.42e-08 ***\nshell         2.0486     0.3672   5.579 2.23e-07 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n```\n\n::: {.columns}\n:::{.column width=\"80%\"}\n\n**Which is the correct equation?**'\n\na) `log(rings)` = 1.41 + 2.04 x `diameter` - 1.33 x `shucked` + 2.04 x `shell`\nb) `log(rings)` = 1.41 + 2.03 x `diameter` - 1.33 x `shucked` + 2.04 x `shell`\nc) `log(rings)` = 1.41 + 2.04 x `diameter` + 1.33 x `shucked` + 2.05 x `shell`\nd) `log(rings)` = 1.41 + 2.03 x `diameter` - 1.33 x `shucked` + 2.05 x `shell`\n:::\n:::{.column width=\"20%\"}\n:::{.fragment .fade-in}\n\n> Attention to detail :)\n\n:::\n\n:::\n:::\n\n## Interpretation\n\nThe equation of our model is:\n\n**`log(rings)` = 1.41 + 2.03 x `diameter` + -1.33 x `shucked` + 2.05 x `shell`**\n\nBelow are three statements. *Given all other predictors are held constant:*\n\n- `rings` changes by $e^{-1.33}$ for every percent increase in `shucked` (weight)\n- `log(rings)` changes by 1.33 for every unit increase in `shucked` (weight)\n- `log(rings)` changes by approximately 1.33% for every percent increase in `shucked` (weight)\n\n::: {.columns}\n:::{.column width=\"40%\"}\n\n**How many statements are correct?**\n\na) none\nb) 1 statement\nc) 2 statements\nd) all of them\n\n:::\n:::{.column width=\"60%\"}\n:::{.fragment .fade-in}\n\n> The first two are correct, the third is not. The natural log percent change appoximation only applies to small $\\beta$ values below |0.25|.\n\n:::\n\n:::\n:::\n\n## The most important question {auto-animate=\"true\"}\n\n**How do you feel about regression so far?**\n\na) Easy\nb) OK\nc) Hard\nd) SOS\n\n# Good work!\n\nThis presentation is based on the [SOLES Quarto reveal.js template](https://github.com/usyd-soles-edu/soles-revealjs) and is licensed under a [Creative Commons Attribution 4.0 International License][cc-by].\n\n<!-- Links -->\n[cc-by]: http://creativecommons.org/licenses/by/4.0/\n",
    "supporting": [
      "abalone-quiz_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}